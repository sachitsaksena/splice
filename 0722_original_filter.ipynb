{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, fnmatch, datetime, subprocess, imp\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = pd.read_csv(fpath+'/061318_exonskipping_library.csv', index_col=0, usecols = ('Identifier number', 'Designed 61-bp target site (37i-24e, AG)')).T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lib = pd.read_csv(fpath+'/061318_exonskipping_library.csv', index_col = 0, usecols = ('Identifier number', 'gene_symbol')).T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = pd.DataFrame(columns = ('umi', 'id'))\n",
    "b6 = pd.DataFrame(columns = ('umi', 'id', 'slice_type', 'num'))\n",
    "b7 = pd.DataFrame(columns = ('umi', 'id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, subdirs, files in os.walk('/home/clara/Desktop/data/post_cas9_mesc'):\n",
    "    fpath = '/home/clara/Desktop/data/post_cas9_mesc/'\n",
    "    for subdir in subdirs:\n",
    "        if subdir is not \"0722_cas9_treated.ipynb\" and 'b6' not in subdir and 'checkpoints' not in subdir and subdir is not '0725_cas9_untreated.ipynb' and 'mesc' not in subdir:\n",
    "            print(subdir)\n",
    "            if int(subdir) in [0,1,2,4,8,9,13] :\n",
    "                subdir = subdir+'/'\n",
    "                sub3 = pd.read_csv(fpath+subdir+'b3', names = ('umi', 'id'), dtype={'id':'Int64'})\n",
    "                sub6 = pd.read_csv(fpath+subdir+'b6', names = ('umi', 'id', 'slice_type', 'num'), dtype={'id':'Int64'})\n",
    "                sub7 = pd.read_csv(fpath+subdir+'b7', names = ('umi', 'id'), dtype={'id':'Int64'})\n",
    "                b3 = pd.concat([b3, sub3])\n",
    "                b6 = pd.concat([b6, sub6])\n",
    "                b7 = pd.concat([b7, sub7])\n",
    "            elif int(subdir)!=5 and int(subdir)!=14:\n",
    "                subdir = subdir+'/'\n",
    "                sub3 = pd.read_csv(fpath+subdir+'b3', names = ('umi', 'id'), dtype={'id':'Int64'})\n",
    "                sub7 = pd.read_csv(fpath+subdir+'b7', names = ('umi', 'id'), dtype={'id':'Int64'})\n",
    "                b3 = pd.concat([b3, sub3])\n",
    "                b7 = pd.concat([b7, sub7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dct = {\n",
    "    'A':'T',\n",
    "    'C':'G',\n",
    "    'T':'A',\n",
    "    'G':'C',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6.to_csv('b6.csv', index=False)\n",
    "b3.to_csv('b3.csv', index=False)\n",
    "b7.to_csv('b7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6 = b6.dropna()\n",
    "b6.slice_type = b6.slice_type.apply(lambda x: x.strip())\n",
    "b6 = b6[~b6.umi.str.contains(\"N\")]\n",
    "b6.umi = b6.umi.apply(lambda x: remove_ggc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6 = pd.read_csv(fpath+'/b6.csv')\n",
    "b3 = pd.read_csv(fpath+'/b3.csv')\n",
    "b7 = pd.read_csv(fpath+'/b7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_nodups = b7.dropna()\n",
    "b7_nodups = b7_nodups[~b7_nodups.umi.str.contains(\"N\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __B7 Analysis Genomic Data__ [gRNA and UMI dictionary]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(umi):\n",
    "    if len(umi) == 0:\n",
    "        return ''\n",
    "    try:\n",
    "        this = match_dct[umi[-1:]]\n",
    "    except:\n",
    "        print(umi)\n",
    "        this = ''\n",
    "    return this + reverse_complement(umi[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_nodups = b7.dropna()\n",
    "b7_nodups = b7_nodups[~b7_nodups.umi.str.contains(\"N\")]\n",
    "b7_nodups.umi = b7_nodups['umi'].apply(lambda x: reverse_complement(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_uniq_count = b7_nodups.groupby('umi')['id'].nunique().reset_index('umi').rename(columns = {'id':'id_count'})\n",
    "b7_uniq_umi = b7_uniq_count.loc[b7_uniq_count.id_count==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_match = b7_nodups[b7_nodups.umi.isin(b7_uniq_umi['umi'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b7_match contains read information, unique matches from umi to id. umis that match to more than one id were eliminated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_nonunique = b7_uniq_count.loc[b7_uniq_count.id_count > 1]\n",
    "b7_nonmatch = b7_nodups[b7_nodups.umi.isin(b7_nonunique['umi'])]\n",
    "b7_percentages = b7_nonmatch.groupby('umi')['id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_percentages = pd.DataFrame(b7_percentages).rename(columns = {'id':'frequency'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: df of umis that predominately map to 1 id, filtered from umis that map to 2 or more ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_rematch = b7_percentages.loc[b7_percentages.frequency > 0.8].reset_index('umi').reset_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_rematch_dict = pd.Series(b7_rematch.id.values, index = b7_rematch.umi).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_nodups['in_rematch'] = b7_nodups.umi.apply(lambda x: True if x in b7_rematch_dict else False)\n",
    "b7_rematch_read = b7_nodups.loc[b7_nodups.in_rematch == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_match(umi, ID):\n",
    "    return b7_rematch_dict[umi] == ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_rematch_read['correct_id'] = b7_rematch_read.apply(lambda x: dict_match(x.umi, x.id),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_rematch_read = b7_rematch_read.loc[b7_rematch_read.correct_id == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_complete = pd.concat([b7_rematch_read, b7_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_complete = pd.read_csv(fpath+'/b7_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_dict = pd.Series(b7_complete.id.values, index=b7_complete.umi).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_complete.to_csv('b7_complete.csv', columns=['umi','id'], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that matches in b7_match only match to one id - shallow level confirmation, just checking one umi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7_match.loc[b7_match.umi == 'AAGGTCTGACTGTCG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genomic_data(df):\n",
    "    #assumes that we do not want read count variation information\n",
    "    df_nodup = df.drop_duplicates().dropna()\n",
    "    df_nodup = df_nodup[~df_nodup.umi.str.contains(\"N\")]\n",
    "    df_nodup.umi = df_nodup.umi.apply(lambda x: reverse_complement(x))\n",
    "    df_uniq_count = df_nodup.groupby('umi').count()\n",
    "    df_uniq_count = df_uniq_count.loc[df_uniq_count.id==1].rename(columns={'id':'count'})\n",
    "    df_uniq_umi = pd.merge(df_nodup,df_uniq_count, how='inner', on=['umi'])\n",
    "    print('number of unique ids:' + str(b7_uniq_umi.id.nunique()))\n",
    "    print('\\n'+'are the number of unique umis equal to the number of rows in df? '+str(b7_uniq_umi.umi.nunique() == b7_uniq_umi.shape[0]))\n",
    "    return df_uniq_umi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: For each duplicated UMI, is it the case that most of the IDs matched to it are of one number, and only a few are of another? (i.e. sequencing or small recombo error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes for some - check TATAGCCTTTTTTTT for an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What the benchmark for recapturing a UMI that was previously mapped to more than one ID?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 standard deviations? average number of reads per umi in the nonmatch dataset\n",
    "- ask Ben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __B3 analysis__ [unspliced data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nodups = b3.dropna()\n",
    "b3_nodups = b3_nodups[~b3_nodups.umi.str.contains(\"N\")]\n",
    "\n",
    "# removed non unique matches first --> should we not do this?? - this doens't do much --> seems like the duplications are evenly distributed across matches and nonmatches\n",
    "b3_uniq_count = b3_nodups.groupby('umi')['id'].nunique().reset_index('umi').rename(columns = {'id':'id_count'})\n",
    "#b3_uniq_count has umi and id_count column - each umi appears once with its matched id count \n",
    "b3_uniq_umi = b3_uniq_count.loc[b3_uniq_count.id_count==1]\n",
    "#b3_uniq_umi contains each unique umi with only one for id_count \n",
    "b3_unique = b3_nodups[b3_nodups.umi.isin(b3_uniq_umi['umi'])]\n",
    "#b3_unique contains read duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_unique.umi.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed nonunique matches --> restored matches that occurred with > 80% probability between on particular UMI - ID pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nonunique = b3_uniq_count.loc[b3_uniq_count.id_count > 1] \n",
    "b3_non_uniq = b3_nodups[b3_nodups.umi.isin(b3_nonunique['umi'])] #b3_unique + b3_non_uniq count == b3 count\n",
    "b3_percentages = b3_non_uniq.groupby('umi')['id'].value_counts(normalize=True)\n",
    "b3_percentages = pd.DataFrame(b3_percentages).rename(columns = {'id':'frequency'})\n",
    "b3_rematch = b3_percentages.loc[b3_percentages.frequency > 0.8].reset_index('umi').reset_index('id') #only contains each umi and id pairing once --> doesn't reflect read count \n",
    "b3_rematch = b3_rematch.drop('frequency', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_rematch_dict = pd.Series(b3_rematch.id.values, index = b3_rematch.umi).to_dict()\n",
    "\n",
    "b3_non_uniq['in_rematch'] = b3_non_uniq.umi.apply(lambda x: True if x in b3_rematch_dict else False)\n",
    "b3_rematch_read = b3_non_uniq.loc[b3_non_uniq.in_rematch == True]\n",
    "b3_rematch_read = b3_rematch_read.drop('in_rematch', axis=1)\n",
    "\n",
    "b3_join = b3_rematch_read.join(pd.Series(b3_rematch.id.values, index = b3_rematch.umi).rename('dict'), on='umi')\n",
    "b3_rematched = b3_join.loc[lambda x: x.id == x.dict]\n",
    "\n",
    "b3_unique_rel = pd.concat([b3_unique, b3_rematched])\n",
    "b3_nodups = b3_unique_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nodups = b3_nodups.drop('dict', axis = 1)\n",
    "b3_nodups.to_csv('b3_80_wrongids.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nodups = pd.read_csv('b3_80_wrongids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nodups['b7_umi'] = b3_nodups['umi'].apply(lambda x: True if x in b7_dict else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What number of the b3 80% UMIs filtered above are also found in the b7 dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b3_nodups.loc[b3_nodups['b7_umi'] == True].umi.nunique(), b3_nodups.loc[b3_nodups['b7_umi'] == False].umi.nunique(), b3_nodups.umi.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_nodups = b3_nodups.loc[b3_nodups['b7_umi'] == True]\n",
    "b3_nodups['b7_id'] = b3_nodups['umi'].apply(lambda x: b7_dict[x])\n",
    "b3_nodups['b3_target'] = b3_nodups.id.apply(lambda x: lib[x]['Designed 61-bp target site (37i-24e, AG)'])\n",
    "b3_nodups['b7_target'] = b3_nodups.b7_id.apply(lambda x: lib[x]['Designed 61-bp target site (37i-24e, AG)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_match = b3_nodups.loc[b3_nodups.b3_target == b3_nodups.b7_target]\n",
    "b3_nomatch = b3_nodups.loc[b3_nodups.b3_target != b3_nodups.b7_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3match = b3_match.umi.nunique()\n",
    "b3nomatch = b3_nomatch.umi.nunique()\n",
    "print(b3match, b3nomatch)\n",
    "print('around '+str(int(float(b3match)/float(b3match+b3nomatch)*100))+' percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_match.to_csv('b3_match.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_match = pd.read_csv(fpath+'/b3_match.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary from UMI to ID of unspliced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_dict = pd.Series(b3_match.b7_id.values,index=b3_match.umi).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below ignores read count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_unique = pd.merge(b7_uniq_umi, b3_nodups, how = 'inner', on = ['umi'])\n",
    "b3_unique = b3_unique[b3_unique.apply(lambda x: lib[x.id_x]['Designed 61-bp target site (37i-24e, AG)'] == lib[x.id_y]['Designed 61-bp target site (37i-24e, AG)'], axis=1)]\n",
    "b3_unique = b3_unique.drop('id_y', axis=1)\n",
    "b3_unique = b3_unique.drop_duplicates('umi', keep=False)\n",
    "b3_unique = b3_unique.rename(columns={'id_x':'id'})\n",
    "b3_unique.id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the b3 analysis remove instances where two umis can match to one id?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOPE: run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_match.loc[b3_match.id == 3563.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __B6 analysis__ [spliced data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Do we need read count information? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ggc(umi):\n",
    "    return umi[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: this chunk of code should maintain read count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "b6_nodups = b6.dropna()\n",
    "b6_nodups.slice_type = b6_nodups.slice_type.apply(lambda x: x.strip())\n",
    "b6_nodups = b6_nodups[~b6_nodups.umi.str.contains(\"N\")]\n",
    "b6_nodups.umi = b6_nodups.umi.apply(lambda x: remove_ggc(x))\n",
    "b6_nodups['b3_umi'] = b6_nodups['umi'].apply(lambda x: True if x in b3_dict else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi_checked = b6_nodups.loc[b6_nodups['b3_umi'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip until new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi = pd.Series(b6_umi_checked.id.values,index=b6_umi_checked.umi).to_dict()\n",
    "# dictionary of mappings from b6 umi to id numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi_checked['in_b3'] = b6_umi_checked['umi'].apply(lambda x: b3_dict[x] == b6_umi[x])\n",
    "# True if the umi maps to the same id as in b3 - else False\n",
    "b6_umi_checked.loc[b6_umi_checked['in_b3'] == False] \n",
    "# not empty right now --> some of these umis do not map to the same id numbers as in b3 --> recombination, need to eliminate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi_checked['b3_id'] = b6_umi_checked.umi.apply(lambda x: b3_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_umi_checked[b6_umi_checked.apply(lambda x: lib[x.id]['Designed 61-bp target site (37i-24e, AG)'] == lib[x.b3_id]['Designed 61-bp target site (37i-24e, AG)'], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_unique.drop('id', axis=1).rename(columns = {'b3_id':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = pd.read_csv('b6_unique_included_reads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique.to_csv('b6_unique_included_reads.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_umi_checked.loc[b6_umi_checked['b3_umi'] == True]\n",
    "b6_unique['real_id'] = b6_unique['umi'].apply(lambda x: b3_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trust the b3_dictionary for now: do not isolate b, process all splice types together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184828"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b6_unique.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.48761408083442"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b6_unique.groupby('id')['umi'].size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_plot = b6_unique.loc[lambda x: x.id != 4657]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_size_inches(20,10)\n",
    "plot = plt.hist(b6_nodups.groupby('umi').size(), bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique.to_csv('b6_match_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at all splice types individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_btype = b6_unique.loc[(b6_unique.slice_type=='b')]\n",
    "b6_btype['b6_target'] = b6_btype.id.apply(lambda x: lib[x]['Designed 61-bp target site (37i-24e, AG)'])\n",
    "b6_btype['b3_target'] = b6_btype.real_id.apply(lambda x: lib[x]['Designed 61-bp target site (37i-24e, AG)'])\n",
    "b6_bmatch = b6_btype.loc[b6_btype.b6_target == b6_btype.b3_target]\n",
    "b6_bnomatch = b6_btype.loc[b6_btype.b6_target != b6_btype.b3_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_bmatch.groupby('real_id').size().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: A normal splice (b type) should have a score of >~70 if it were a nearly normal splice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = b6_bmatch.loc[b6_bmatch.num > 70].shape[0]\n",
    "nomatch = b6_bnomatch.loc[b6_bnomatch.num > 70].shape[0]\n",
    "print(match, nomatch)\n",
    "print(str(int(float(match)/float((match+nomatch))*100))+' percent match with restriction to score above 60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plt.hist(b6_unique.num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_bmatch_dict = pd.Series(b6_bmatch.id.values, index = b6_bmatch.umi).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_ctype = b6_unique.loc[b6_unique.slice_type=='c']\n",
    "b6_ctype['b_present'] = b6_ctype.umi.apply(lambda x: True if x in b6_bmatch_dict else False)\n",
    "b6_c_and_b = b6_ctype.loc[b6_ctype.b_present == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_ctype.loc[b6_ctype.b_present==True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_c_and_b['real_id'] = b6_c_and_b.umi.apply(lambda x: b6_bmatch_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_c_and_b.groupby('real_id').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_cryptic = b6_unique.loc[b6_unique.slice_type=='cryptic']\n",
    "b6_cryptic['b_present'] = b6_cryptic.umi.apply(lambda x: True if x in b6_bmatch_dict else False)\n",
    "b6_cryptic_and_b = b6_cryptic.loc[b6_cryptic.b_present == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_cryptic.loc[b6_cryptic.b_present ==True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_cryptic_and_b['real_id'] = b6_cryptic_and_b.umi.apply(lambda x: b6_bmatch_dict[x])\n",
    "b6_cryptic_and_b.groupby('real_id').size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_match = pd.concat([b6_bmatch, b6_c_and_b, b6_cryptic_and_b])\n",
    "b6_csv = b6_match[['umi','real_id','slice_type']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_csv.to_csv('b6_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of UMIs at each stage of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = [b7.dropna().shape[0], b3.dropna().shape[0], b6.dropna().shape[0], b7_complete.shape[0], b3_match.shape[0], b6_unique.shape[0], \n",
    "          b6_bmatch.shape[0]+b6_c_and_b.shape[0]+b6_cryptic_and_b.shape[0]]\n",
    "x = [1,2,3,4,5,6,7]\n",
    "f = plt.figure()\n",
    "f.set_size_inches(20, 10)\n",
    "f.suptitle('Raw UMI read count at each stage of cas9 treated data processing (mesc)', y = 1.05)\n",
    "plt.bar(x, height)\n",
    "plt.xticks([1,2,3,4,5,6,7], ['b7', 'b3', 'b6','b7 nearly unique matches (>80%)', 'b3 (>80%) and matched with b7 target id','b6 UMIs confirmed by b3 dataset',\n",
    "                                 'b6 UMIs that match target ids in b3'], rotation = 30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [b7.dropna(), b3.dropna(), b6.dropna(), b7_complete, b3_match, b6_unique, pd.concat([b6_bmatch,b6_c_and_b,b6_cryptic_and_b])]\n",
    "height = np.array(map(lambda x: x.umi.nunique(), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6,7]\n",
    "f = plt.figure()\n",
    "f.set_size_inches(20, 10)\n",
    "f.suptitle('UMI unique counts at each stage of cas9 treated data processing (mesc)', y = 1.05)\n",
    "plt.bar(x, height)\n",
    "plt.xticks([1,2,3,4,5,6,7], ['b7', 'b3', 'b6','b7 nearly unique matches (>80%)', 'b3 (>80%) and matched with b7 target id','b6 UMIs confirmed by b3 dataset',\n",
    "                                 'b6 UMIs that match target ids in b3'], rotation = 30)\n",
    "rects = ax.patches\n",
    "labels = height\n",
    "for rect, label in zip(rects, labels):\n",
    "    hght = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2, hght + 5, label,     \n",
    "    ha='center', va='bottom')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: Code removes read count information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_nodups = b6.drop_duplicates().dropna()\n",
    "b6_nodups.slice_type = b6_nodups.slice_type.apply(lambda x: x.strip())\n",
    "b6_nodups = b6_nodups[~b6_nodups.umi.str.contains(\"N\")]\n",
    "b6_nodups.umi = b6_nodups.umi.apply(lambda x: remove_ggc(x))\n",
    "b6_unique = pd.merge(b3_unique, b6_nodups, how = 'inner', on = ['umi']) # eliminates UMIs that cannot be used (not matched by b7 and b3)\n",
    "b6_unique = b6_unique[b6_unique.apply(lambda x: lib[x.id_x]['gene_symbol'] == lib[x.id_y]['gene_symbol'], axis=1)]\n",
    "b6_unique = b6_unique.drop('id_y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_unique.drop('count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_unique.rename(columns={'id_x':'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference in these numbers is due to the fourth column, or the third and fourth column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b6_unique.umi.nunique(), b6_unique.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi_dict = pd.Series(b6_unique.id.values,index=b6_unique.umi).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_umi = pd.Series(b6_unique.id.values, index=b6_unique.umi).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to confirm that all the UMIs in the readcount removed set that are duplicated also have the same id - they only vary by the third or fourth column due to cell division duplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique['uniq_umi'] = b6_unique['umi'].apply(lambda x: b3_dict[x] == b6_umi[x])\n",
    "b6_unique.loc[b6_unique['uniq_umi'] == False].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Would two reads from the same UMI, id, splice_type have the same score if they were from the same molecule? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely yes? If they're from the same molecule, the alignment should be similar, and so should the score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How do we want to store UMI, ID --> splice_type --> fourth column information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id_dict --> first level key is the id, second key is the splice_type, third is 'num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_unique = b6_unique.drop('uniq_umi', axis=1) # not needed if b6 is imported from csv --> addition uniq_umi column comes from confirming the duplicated UMIs don't vary by UMI\n",
    "df2 = b6_unique.groupby(['id','slice_type']).count().reset_index(['slice_type','id']).drop('umi', axis=1)\n",
    "id_dict = df2.groupby('id')[['slice_type','num']].apply(lambda x: x.set_index(['slice_type']).to_dict(orient='index')).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b6_dict --> first key: tuple of umi and id, second key: splice_type, third key: 'num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = b6_unique.groupby(['umi','id','slice_type']).count().reset_index(['slice_type','umi','id'])\n",
    "b6_dict = df.groupby(['umi','id'])[['slice_type','num']].apply(lambda x: x.set_index(['slice_type']).to_dict(orient='index')).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Assuming all the analysis above is correct so far, which genes have the most number of perfect exon skipping? Print ID and gene symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_c_df = df2.loc[df2.slice_type=='c'].sort_values('num', ascending=False)\n",
    "splice_c_df = splice_c_df.set_index('id',drop=False)\n",
    "splice_c_df.id.apply(lambda x: gene_lib[x]['gene_symbol'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
